# 理数探求

## 概要
このリポジトリは、沼津東高校2024年度理数探求情報班のリポジトリです。すでに探究活動は終了してるので基本的に内容の変更は行いません。

## ファイル内容
### データセット
- dataディレクトリ
  - MNISTのデータセットzipファイル
  - MNISTデータセットをnumpy配列に変換するpythonファイル
- data_cifar10ディレクトリ
  - cifar10のデータセットzipファイル
- load_cifar10.py
  - cifar10データセットをnumpyファイルに変換する
### ネットワーク関連
- panams_init.py
  - 重みやバイアスなどのパラメーターを初期化するファイル
  - 重み初期化の手法は`weight_initialization()`関数に手法を記述した関数を持つクラスを定義することで追加できます
  - 戻り値paramsは各層に必要なパラメーターを保持したdictオブジェクトです
  - それぞれのkey名は以下の通りです。層番号は層の種類毎に1から始まります
    - 畳み込み層のフィルタ: F<層番号>
    - 畳み込み層のバイアス: Cb<層番号>
    - 全結合層の重み: W<層番号>
    - 全結合層のバイアス: b<層番号>
    - バッチ正規化層 バッチ平均の移動平均: move_m<層番号>
    - バッチ正規化層 バッチ分散の移動平均: move_v<層番号>
    - バッチ正規化層 スケーリング: gamma<層番号>
    - バッチ正規化層 シフト: beta<層番号>
- layer.py
  - 層ごとに順伝播、逆伝播の処理を記述されたクラスが定義されています
  - 以下の層を実装しています
    - ReLU関数
    - LeakyReLU関数(実装はしていますが現在は対応していません)
    - 全結合層
    - 畳み込み層
    - 最大プーリング層
    - 平坦化層
    - バッチ正規化層
    - ソフトマックスと交差エントロピー関数の層
    - ドロップアウト
    - Toba層(平坦化層のノードを削除した際の対応を行う)
  - いずれの層も必ず`forward()`関数と`backward()`関数を持ちます
    - `forward()`: 順伝播を表す関数
    - `backward()`: 逆伝播を表す関数
        
- model.py
  - 層のクラスを組み合わせてネットワークを構成し、評価を行う
    
- Toba.py
  - 本研究で考案したTobaの処理を記述
- trainer.py
  - Optimizerクラス
    - 勾配降下法における最適化手法のクラス
    - ミニバッチSGDとAdamを実装
  - Schedulerクラス
    - 学習率スケジューラーのクラス
    - 指数関数、cosine関数、マルチステップを実装
  - Trainerクラス
    - 以上のクラスをまとめて、学習およびTobaプルーニングを実行するためのクラス

### 実験関連
- experiment**.py
  - 実験を行い、その結果をExcelファイルに書き込む
- exp**.xlsx
  - 実験結果を保存したExcelファイル
 
### その他
- gpu.py
  - cupyを使うか、numpyを使うかの分岐





